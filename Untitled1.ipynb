{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51abc184-e75f-4b00-9a3a-6306752e0f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/maxim/.cache/huggingface/datasets/TopicNet___csv/TopicNet--Lenta-5798a04907214574/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7949328aef424593b50412f81a8c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"TopicNet/Lenta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ece8e74f-95e1-4330-9b98-40527f429a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 449272,\n",
       " 'url': 'https://lenta.ru/news/2013/01/01/fire2/',\n",
       " 'title': 'В ЮАР четыре тысячи человек остались без крова из-за пожара',\n",
       " 'text': 'В ЮАР произошел пожар, в результате которого погибли три человека, один получил ожоги, а четыре тысячи человек остались бездомными. Об этом 1 января сообщает Agence France-Presse. Пожар произошел в бедном районе Кейптауна. По информации Associated Press, этот район скученно застроен хижинами, зачастую возведенными самовольно. Для освещения, отопления и приготовления пищи там часто используются свечи, газовые горелки, керосиновые лампы и иные пожароопасные устройства. По предварительным данным, причиной возгорания стало неосторожное обращение с огнем в состоянии алкогольного опьянения. Распространению пламени способствовал сильный ветер. В настоящее время на месте работают команды спасателей. Они раздают пострадавшим продуктовые наборы, одежду и строительные материалы.',\n",
       " 'topic': 'Мир',\n",
       " 'tags': 'Все',\n",
       " 'lemmatized': 'юар произойти пожар результат погибнуть ожог тысяча остаться бездомный presse пожар произойти бедный район кейптаун press район скученно застроить хижина зачастую возвести самовольно освещение отопление приготовление пища часто использоваться свеча газовый горелка керосиновый лампа иной пожароопасный устройство предварительный причина возгорание неосторожный обращение огонь состояние алкогольный опьянение распространение пламя способствовать сильный ветер настоящее место команда спасатель раздавать пострадавший продуктовый набор одежда строительный материал',\n",
       " 'year': 2013,\n",
       " 'month': 1,\n",
       " 'day': 1,\n",
       " 'time_n': 449272,\n",
       " 'lemmatized_title': 'в юар четыре тысяча человек остаться без кров из за пожар',\n",
       " 'topmine': 'место_настоящее состояние_алкогольный_опьянение предварительный_причина состояние_алкогольный результат_пожар приготовление_пища самовольно_возвести результат_погибнуть остаться_тысяча часто_использоваться причина_возгорание пожар_произойти пожар_произойти алкогольный_опьянение пожар_presse сильный_ветер продуктовый_набор обращение_огонь строительный_материал результат_пожар_погибнуть результат_пожар_произойти',\n",
       " 'vw_text': '0 |@word юар произойти пожар результат погибнуть ожог тысяча остаться бездомный presse пожар произойти бедный район кейптаун press район скученно застроить хижина зачастую возвести самовольно освещение отопление приготовление пища часто использоваться свеча газовый горелка керосиновый лампа иной пожароопасный устройство предварительный причина возгорание неосторожный обращение огонь состояние алкогольный опьянение распространение пламя способствовать сильный ветер настоящее место команда спасатель раздавать пострадавший продуктовый набор одежда строительный материал |@ngramm место_настоящее состояние_алкогольный_опьянение предварительный_причина состояние_алкогольный результат_пожар приготовление_пища самовольно_возвести результат_погибнуть остаться_тысяча часто_использоваться причина_возгорание пожар_произойти пожар_произойти алкогольный_опьянение пожар_presse сильный_ветер продуктовый_набор обращение_огонь строительный_материал результат_пожар_погибнуть результат_пожар_произойти',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cac1288-a920-4dd4-92f9-03fd3d2aba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['url', 'tags', 'lemmatized', 'year', 'month', 'day', 'time_n', 'lemmatized_title', 'topmine', 'vw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38922b2b-2403-4cf4-b2e3-7d81ff773a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ffcc60b-e5cc-4afe-89e6-21c741a94fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 449272,\n",
       " 'text': 'В ЮАР произошел пожар, в результате которого погибли три человека, один получил ожоги, а четыре тысячи человек остались бездомными. Об этом 1 января сообщает Agence France-Presse. Пожар произошел в бедном районе Кейптауна. По информации Associated Press, этот район скученно застроен хижинами, зачастую возведенными самовольно. Для освещения, отопления и приготовления пищи там часто используются свечи, газовые горелки, керосиновые лампы и иные пожароопасные устройства. По предварительным данным, причиной возгорания стало неосторожное обращение с огнем в состоянии алкогольного опьянения. Распространению пламени способствовал сильный ветер. В настоящее время на месте работают команды спасателей. Они раздают пострадавшим продуктовые наборы, одежду и строительные материалы.',\n",
       " 'topic': 'Мир',\n",
       " 'id': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28060b49-7c50-45f6-aed6-da7408200f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92c3ca40-7a15-449e-a280-84927a6fdf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('DeepPavlov/rubert-base-cased-sentence')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased-sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f3653de-300a-4db0-bf22-e8349b2497eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = [len(str(i).split()) for i in dataset['train']['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8fd77ca-4a44-44f2-8ba8-37793037a873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(seq_len).hist(bins = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "657100db-5c4c-4946-a806-ba999b4f53ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset['train']['topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d76baf8b-fad5-453e-9542-0b09f67eeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "920deeb8-21e4-49a8-b2e1-72f43274d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c5bef4a-efd8-4956-a302-7484af8a6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f872811f-6454-443f-96b1-b2c589c6a0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               43492\n",
       "Мир                  41915\n",
       "Бывший СССР          23262\n",
       "Спорт                21397\n",
       "Экономика            21392\n",
       "Культура             19408\n",
       "Наука и техника      18764\n",
       "Интернет и СМИ       17378\n",
       "Из жизни             12222\n",
       "Силовые структуры    11223\n",
       "Дом                   9318\n",
       "Ценности              7581\n",
       "Бизнес                7375\n",
       "Путешествия           6370\n",
       "69-я параллель        1268\n",
       "Крым                   666\n",
       "Культпросвет           340\n",
       "Легпром                114\n",
       "Библиотека              65\n",
       "Оружие                   3\n",
       "ЧМ-2014                  2\n",
       "МедНовости               1\n",
       "Сочи                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed823e50-4a34-4496-b9b5-ffe1821cad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_pandas.groupby('topic').filter(lambda g: len(g) > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9e4674d-7bd4-4450-8a95-cce2bf675a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               43492\n",
       "Мир                  41915\n",
       "Бывший СССР          23262\n",
       "Спорт                21397\n",
       "Экономика            21392\n",
       "Культура             19408\n",
       "Наука и техника      18764\n",
       "Интернет и СМИ       17378\n",
       "Из жизни             12222\n",
       "Силовые структуры    11223\n",
       "Дом                   9318\n",
       "Ценности              7581\n",
       "Бизнес                7375\n",
       "Путешествия           6370\n",
       "69-я параллель        1268\n",
       "Крым                   666\n",
       "Культпросвет           340\n",
       "Легпром                114\n",
       "Библиотека              65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39453a0c-a3ef-4910-b248-9858888cd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fdd5bbd3-6ffe-48f9-bae5-e27cde5f687a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 11, 11, ...,  9, 16,  3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(df_pandas['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1abd10c-ad9a-465d-b1eb-65849f55e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas['topic'] = le.fit_transform(df_pandas['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "081767d3-4dc3-4b50-bf9f-07396bf0cf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В ЮАР произошел пожар, в результате которого п...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Давка в крупнейшем городе Кот-д'Ивуара Абиджан...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Политические партии и общественные организации...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Премьер-министр Грузии Бидзина Иванишвили в но...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Полиция отпустила всех участников акции \"Страт...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  topic\n",
       "0  В ЮАР произошел пожар, в результате которого п...     11\n",
       "1  Давка в крупнейшем городе Кот-д'Ивуара Абиджан...     11\n",
       "2  Политические партии и общественные организации...     11\n",
       "3  Премьер-министр Грузии Бидзина Иванишвили в но...      3\n",
       "4  Полиция отпустила всех участников акции \"Страт...     14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5f4a395-a946-4b89-a094-da5f910b4ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(le.fit_transform(df_pandas['topic']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4c96c7a5-e60f-48d1-8c26-ace95413eccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_pandas['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fd0c0d2e-779c-408b-8dca-be78f1467ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_pandas['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1f1e05e-6442-4a5e-bea2-e9939a39bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_pandas['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8475b51-4ae7-4e09-90d2-1f93b1307cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a81d919-e746-45f4-9207-ebac352684e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, x_test, y, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "240e9fd2-67f4-4d32-9afe-da683d35fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    x_train.values,\n",
    "    max_length = 300,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    x_val.values,\n",
    "    max_length = 300,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    x_test.values,\n",
    "    max_length = 300,\n",
    "    padding = 'max_length',\n",
    "    truncation = True\n",
    ")\n",
    "\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(y_train.values)\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(y_val.values)\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(y_test.values)\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n",
    "\n",
    "val_data =  TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06d79c09-35f9-4bc2-ad07-b568902d5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        self.fc2 = nn.Linear(512,19)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, sent_id, mask):\n",
    "        _, cls_hs = self.bert(sent_id, attention_mask = mask, return_dict = False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee31eaab-ab7e-42d2-a7fd-1e5a4a25b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BERT_Arch(bert)\n",
    "\n",
    "model = model.to(device)\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "               lr= 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "edab21ff-d5a1-4ccb-85d3-124e326eab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.94051149 214.2831216    1.88081432   0.59625893   1.48879026\n",
      "   1.13501562   0.79822871  20.85305546  40.61575507   0.71468781\n",
      " 121.84726522   0.33093037   0.73925893   2.17736879   0.31892279\n",
      "   1.2361668    0.64825897   1.82986176   0.64839425]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18d2b75a-e775-4c98-8ef1-c44f76ede636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99eeef27-d5a9-42a6-96fb-4892e815ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "weights = weights.to(device)\n",
    "cross_entropy = nn.CrossEntropyLoss(weight=weights)\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a15516b-f77e-40fb-88f8-d6773e13fcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    total_preds = []\n",
    "    \n",
    "    for step, batch in tqdm(enumerate(train_dataloader), total = len(train_dataloader)):\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        sent_id,mask,labels = batch\n",
    "        model.zero_grad()\n",
    "        preds = model(sent_id, mask)\n",
    "        loss = cross_entropy(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        total_preds.append(preds)\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    \n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7da3a7d7-4bf2-4a22-a3a7-a3c42fe8f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0,0\n",
    "    total_preds = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(val_dataloader), total = len(val_dataloader)):\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            preds = model(sent_id, mask)\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    total_preds = np.concatenate(total_preds, axis = 0)\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27fc4bdb-25cb-4322-b702-2e9431dcdffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model.load_state_dict(torch.load(<span style=\"color: #808000; text-decoration-color: #808000\">'saved_weights.pt'</span>))                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/maxim/.local/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">791</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 788 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'encoding'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> pickle_load_args.keys():                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 789 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>pickle_load_args[<span style=\"color: #808000; text-decoration-color: #808000\">'encoding'</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">'utf-8'</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 790 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 791 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> _open_file_like(f, <span style=\"color: #808000; text-decoration-color: #808000\">'rb'</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> opened_file:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 792 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_zipfile(opened_file):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 793 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># The zipfile reader is going to advance the current file position.</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If we want to actually tail call to torch.jit.load, we need to</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/maxim/.local/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">271</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open_file_like</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 268 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 269 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open_file_like</span>(name_or_buffer, mode):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 270 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_path(name_or_buffer):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 271 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _open_file(name_or_buffer, mode)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'w'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> mode:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _open_buffer_writer(name_or_buffer)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/maxim/.local/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">252</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 249 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 250 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">_open_file</span>(_opener):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 251 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name, mode):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 252 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(name, mode))                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 253 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 254 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__exit__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 255 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.file_like.close()                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: <span style=\"color: #008000; text-decoration-color: #008000\">'saved_weights.pt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model.load_state_dict(torch.load(\u001b[33m'\u001b[0m\u001b[33msaved_weights.pt\u001b[0m\u001b[33m'\u001b[0m))                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/maxim/.local/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m791\u001b[0m in \u001b[92mload\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 788 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mencoding\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m pickle_load_args.keys():                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 789 \u001b[0m\u001b[2m│   │   \u001b[0mpickle_load_args[\u001b[33m'\u001b[0m\u001b[33mencoding\u001b[0m\u001b[33m'\u001b[0m] = \u001b[33m'\u001b[0m\u001b[33mutf-8\u001b[0m\u001b[33m'\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 790 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 791 \u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m _open_file_like(f, \u001b[33m'\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m'\u001b[0m) \u001b[94mas\u001b[0m opened_file:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 792 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m _is_zipfile(opened_file):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 793 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The zipfile reader is going to advance the current file position.\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/maxim/.local/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m271\u001b[0m in \u001b[92m_open_file_like\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 268 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 269 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_open_file_like\u001b[0m(name_or_buffer, mode):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 270 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m _is_path(name_or_buffer):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 271 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _open_file(name_or_buffer, mode)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 272 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 273 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mw\u001b[0m\u001b[33m'\u001b[0m \u001b[95min\u001b[0m mode:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 274 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _open_buffer_writer(name_or_buffer)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/maxim/.local/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m252\u001b[0m in \u001b[92m__init__\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 249 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 250 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92m_open_file\u001b[0m(_opener):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 251 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, name, mode):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 252 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(\u001b[96mopen\u001b[0m(name, mode))                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 253 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 254 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__exit__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 255 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.file_like.close()                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \u001b[32m'saved_weights.pt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('saved_weights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "24ae112c-d3e3-4ae6-9c80-a042100dee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3690/3690 [35:21<00:00,  1.74it/s]\n",
      "100%|███████████████████████████████████████| 1582/1582 [14:26<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 1.184\n",
      "Validation loss: 0.922\n",
      "\n",
      " Epoch2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3690/3690 [34:57<00:00,  1.76it/s]\n",
      "100%|███████████████████████████████████████| 1582/1582 [14:23<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training loss: 0.912\n",
      "Validation loss: 0.854\n",
      "\n",
      " Epoch3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                        | 90/3690 [00:51<34:33,  1.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> epoch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>):                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'\\n Epoch{:} / {:}'</span>.format(epoch+<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, epochs))                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 9 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>train_loss, _ = train()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>valid_loss, _ = evaluate()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> valid_loss &lt; best_valid_loss:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model.zero_grad()                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>preds = model(sent_id, mask)                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = cross_entropy(preds, labels)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>total_loss += loss.item()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss.backward()                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.nn.utils.clip_grad_norm_(model.parameters(), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span>)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>optimizer.step()                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m9\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[94mfor\u001b[0m epoch \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[94m4\u001b[0m):                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m'\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m Epoch\u001b[0m\u001b[33m{:}\u001b[0m\u001b[33m / \u001b[0m\u001b[33m{:}\u001b[0m\u001b[33m'\u001b[0m.format(epoch+\u001b[94m1\u001b[0m, epochs))                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 9 \u001b[2m│   \u001b[0mtrain_loss, _ = train()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   \u001b[0mvalid_loss, _ = evaluate()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m valid_loss < best_valid_loss:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m12\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   \u001b[0mmodel.zero_grad()                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0mpreds = model(sent_id, mask)                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0mloss = cross_entropy(preds, labels)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 \u001b[2m│   │   \u001b[0mtotal_loss += loss.item()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0mloss.backward()                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mtorch.nn.utils.clip_grad_norm_(model.parameters(), \u001b[94m1.0\u001b[0m)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0moptimizer.step()                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "for epoch in range(4):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Validation loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "54f704bd-ef10-4164-bc7e-4e8b70a383f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('saved_weights.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "773b6cdd-4b95-4f23-915d-be45ed64d903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42168"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c78033-66cd-49c1-9c44-e00cfb49878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# list_seq = np.array_split(test_seq, 1)\n",
    "# list_mask = np.array_split(test_mask, 1)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(list_seq)):\n",
    "    with torch.no_grad():\n",
    "        preds = model(list_seq[i].to(device), list_mask[i].to(device))\n",
    "        predictions.append(np.argmax(preds.detach().cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9409ce75-6b34-4386-aadc-acbcd0e2fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "67ae6e93-6652-4f6d-9dc5-60369b186823",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_preds = [item[1] for sublist in predictions for item in sublist]\n",
    "flat_preds = (flat_preds - min(flat_preds)) / (max(flat_preds) - min(flat_preds))\n",
    "test_df['confidence'] = flat_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "228ad1a8-5038-43fa-89bc-c622acdfff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.01       203\n",
      "           1       0.21      0.70      0.32        10\n",
      "           2       0.00      0.00      0.00      1180\n",
      "           3       0.00      0.00      0.00      3722\n",
      "           4       0.00      0.00      0.00      1491\n",
      "           5       0.00      0.00      0.00      1956\n",
      "           6       0.00      0.00      0.00      2780\n",
      "           7       0.00      0.00      0.00       107\n",
      "           8       0.00      0.00      0.00        54\n",
      "           9       0.00      0.00      0.00      3105\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00      6706\n",
      "          12       0.00      0.00      0.00      3002\n",
      "          13       0.00      0.00      0.00      1019\n",
      "          14       0.00      0.00      0.00      6959\n",
      "          15       0.00      0.00      0.00      1796\n",
      "          16       0.00      0.00      0.00      3424\n",
      "          17       0.00      0.00      0.00      1213\n",
      "          18       0.00      0.00      0.00      3423\n",
      "\n",
      "    accuracy                           0.00     42168\n",
      "   macro avg       0.01      0.09      0.02     42168\n",
      "weighted avg       0.00      0.00      0.00     42168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxim/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/maxim/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_df['pred'] = test_df['confidence'].apply(lambda x: 1 if x>0.9 else 0)\n",
    "\n",
    "print(classification_report(y_test, test_df['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3bec4985-3b2d-416d-bdbb-30a066d3e02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3531"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8a00054-9012-4487-ad15-aa6a834544a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0466684-8cf3-469c-9003-7d600ad81a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df9a86-17d7-4064-b3ef-9d11b73be92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3eb98-514b-4b0a-8136-d18cf0687e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(16):\n",
    "    print('\\n Epoch{:} / {:}'.format(epoch+1, epochs))\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print(f'\\nTraining loss: {train_loss:.3f}')\n",
    "    print(f'Validation loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9c60d-62e7-4075-9533-7cadeadc0dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
